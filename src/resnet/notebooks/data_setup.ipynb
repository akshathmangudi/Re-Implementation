{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2539c42-c6d5-4b8f-a588-a4da4e7cc04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e86f0-537f-4fe5-82dc-17d6c676519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2e326-d18f-411f-844b-9d089a71c92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random_seed = torch.manual_seed(0)\n",
    "\n",
    "def data_loader(data_dir, batch_size, random_seed=random_seed, valid_size=0.1, shuffle=True, test=False): \n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        std=[0.2023, 0.1994, 0.2010],\n",
    "    )\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), \n",
    "        transforms.ToTensor(), \n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    if test: \n",
    "        dataset = CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        return data_loader\n",
    "\n",
    "    train_dataset = CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
    "    valid_dataset = CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return (train_dataloader, valid_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
