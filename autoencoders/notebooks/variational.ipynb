{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hTOfMl4zWTyv",
        "outputId": "9b027895-c8b6-4696-c374-9d6583b3445a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7a7Go7BZW7n5"
      },
      "outputs": [],
      "source": [
        "transform = torchvision.transforms.ToTensor()\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root=\"./data\",\n",
        "                                           train=True,\n",
        "                                           download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"./data\",\n",
        "                                           train=False,\n",
        "                                           download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ekptuJ9GX45M"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=32,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                          batch_size=32,\n",
        "                                          shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ReP857spZnnb"
      },
      "outputs": [],
      "source": [
        "class SimpleAE(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden = 8\n",
        "\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(784, 256),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Linear(256, 64),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(64, self.hidden),\n",
        "            torch.nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.hidden, 64),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Linear(64, 256),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Linear(256, 784),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encode = self.encoder(x)\n",
        "        decode = self.decoder(x)\n",
        "        return encode, decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "RbifLNmVYsZe"
      },
      "outputs": [],
      "source": [
        "# We will create the derived class where we will add our mu, sigma\n",
        "\n",
        "class VariationalAE(SimpleAE):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # For our reparametrization trick\n",
        "        self.mu = torch.nn.Linear(self.hidden, self.hidden)\n",
        "        self.sigma = torch.nn.Linear(self.hidden, self.hidden)\n",
        "\n",
        "\n",
        "    def reparametrize(self, mu, sigma):\n",
        "        std = torch.exp(0.5*sigma)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        mu = self.mu(encoded)\n",
        "        sigma = self.sigma(encoded)\n",
        "\n",
        "        eta = self.reparametrize(mu, sigma)\n",
        "        decoded = self.decoder(eta)\n",
        "        return encoded, decoded, mu, sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "CowZZcSMZI59"
      },
      "outputs": [],
      "source": [
        "def loss(x_p, x, mu, sigma):\n",
        "    bce = torch.nn.functional.binary_cross_entropy(x_p, x.view(-1, 784), reduction=\"sum\")\n",
        "    # KLD is the Kullback-Leibler divergence between the latent variables and the standard Gaussian\n",
        "    kld = -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\n",
        "    return bce + kld"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8__cCA0b7s-",
        "outputId": "1bf698c0-4a39-4f8c-ebe7-ccbea95079a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 out of 10, Loss: 1466.954576171875\n",
            "Epoch 2 out of 10, Loss: 1161.0882458007814\n",
            "Epoch 3 out of 10, Loss: 1101.2987404622395\n",
            "Epoch 4 out of 10, Loss: 1070.334257747396\n",
            "Epoch 5 out of 10, Loss: 1051.8157483072916\n",
            "Epoch 6 out of 10, Loss: 1039.3870731770833\n",
            "Epoch 7 out of 10, Loss: 1028.581184407552\n",
            "Epoch 8 out of 10, Loss: 1021.4821490885416\n",
            "Epoch 9 out of 10, Loss: 1015.2931165039063\n",
            "Epoch 10 out of 10, Loss: 1008.6276\n"
          ]
        }
      ],
      "source": [
        "var_ae = VariationalAE().to(device)\n",
        "optimizer = torch.optim.Adam(var_ae.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "criterion = torch.nn.MSELoss(reduction=\"sum\")\n",
        "num_epochs = 10\n",
        "\n",
        "# Because of the extra added KLD term, the error is higher than usual.\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        images, _ = data\n",
        "        images = images.to(device)\n",
        "        images = images.view(images.size(0), -1)\n",
        "        encoded, decoded, mu, sigma = var_ae(images)\n",
        "        kld = -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\n",
        "        loss = criterion(decoded, images) + kld\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "    e_loss = total_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch + 1} out of {num_epochs}, Loss: {e_loss}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
